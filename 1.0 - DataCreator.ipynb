{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import yaml\n",
    "from Data_Creator_Helper import * \n",
    "from FilterEvents import filter_events\n",
    "from Data_Creator_Preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a csv for all stays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patients = read_patients_data(f'./rawdata/')\n",
    "admissions = read_admission_data(f'./rawdata/')\n",
    "stays = read_icustays_data(f'./rawdata/')\n",
    "\n",
    "stays = remove_icustays_with_transfers(stays)\n",
    "stays = merge_on_subject_admission(stays, admissions)\n",
    "stays = merge_on_subject(stays, patients)\n",
    "stays = filter_admissions_on_nb_icustays(stays)\n",
    "stays = add_age_to_icustays(stays)\n",
    "stays = add_inhospital_mortality_to_icustays(stays)\n",
    "stays = filter_icustays_on_age(stays)\n",
    "stays = add_inunit_mortality_to_icustays(stays)\n",
    "stays.to_csv(os.path.join('./data/', 'all_stays.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a csv for all diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diagnoses = read_icd_diagnoses_data(f'./rawdata/')\n",
    "diagnoses = filter_diagnoses_on_stays(diagnoses, stays)\n",
    "diagnoses.to_csv(os.path.join('./data/', 'all_diagnoses.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a csv with diagnoses count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = count_icd_codes(diagnoses, output_path=os.path.join('./data/', 'diagnosis_counts.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreass2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:72: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "phenotypes = add_hcup_ccs_2015_groups(diagnoses, yaml.load(open('resources/hcup_ccs_2015_definitions.yaml', 'r')))\n",
    "make_phenotype_label_matrix(phenotypes, stays).to_csv(os.path.join('./data', 'phenotype_labels.csv'),\n",
    "                                                      index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a csv file with stays for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT 33798 of 33798...DONE!\n"
     ]
    }
   ],
   "source": [
    "subjects = stays.SUBJECT_ID.unique()\n",
    "break_up_stays_by_subject(stays, './data/', subjects=subjects, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a csv file with diagnoses for each patient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT 33798 of 33798...DONE!\n"
     ]
    }
   ],
   "source": [
    "break_up_diagnoses_by_subject(phenotypes, './data/', subjects=subjects, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a csv file with events for each patient\n",
    "\n",
    "This will make a folder for each patient. Each folder is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is for testing, choosing around 1000 patients and one event type only. \n",
    "\n",
    "#event_data = ['CHARTEVENTS', 'LABEVENTS', 'OUTPUTEVENTS']\n",
    "#pat_idx = np.random.choice(patients.shape[0], size=1000)\n",
    "#patients = patients.iloc[pat_idx]\n",
    "#stays = stays.merge(patients[['SUBJECT_ID']], left_on='SUBJECT_ID', right_on='SUBJECT_ID')\n",
    "#event_data = [event_data[2]]\n",
    "#print('Using only', stays.shape[0], 'stays and only', event_data[0], 'table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished processing LABEVENTS: ROW 27854054 of 27854056...last write (394668) 73 rows for subject 96442...DONE!\n"
     ]
    }
   ],
   "source": [
    "path_to_items = f'./rawdata/D_LABITEMS.csv'\n",
    "\n",
    "event_tables  = ['LABEVENTS']\n",
    "items_to_keep = set(\n",
    "    [int(itemid) for itemid in pd.read_csv(path_to_items, header=0, index_col=0)['ITEMID'].unique()]) if path_to_items else None\n",
    "\n",
    "for table in event_tables:\n",
    "    read_events_table_and_break_up_by_subject('./rawdata/', table, './data/', items_to_keep=items_to_keep,\n",
    "                                              subjects_to_keep=subjects, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished processing CHARTEVENTS: ROW 330712482 of 330712484...last write (3168090) 287 rows for subject 99781...DONE!\n",
      "finished processing OUTPUTEVENTS: ROW 4349217 of 4349219...last write (351140) 39 rows for subject 68375...DONE!\n"
     ]
    }
   ],
   "source": [
    "path_to_items = f'./rawdata/D_ITEMS.csv'\n",
    "\n",
    "event_tables  = ['CHARTEVENTS', 'OUTPUTEVENTS']\n",
    "items_to_keep = set(\n",
    "    [int(itemid) for itemid in pd.read_csv(path_to_items, header=0, index_col=0)['ITEMID'].unique()]) if path_to_items else None\n",
    "\n",
    "for table in event_tables:\n",
    "    read_events_table_and_break_up_by_subject('./rawdata/', table, './data/', items_to_keep=items_to_keep,\n",
    "                                              subjects_to_keep=subjects, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove data from events\n",
    "This is based on the assumptions from the github project. \n",
    "The assumptions are:\n",
    "* There is one-to-one mapping between HADM_ID and ICUSTAY_ID in `stays.csv` files.\n",
    "* HADM_ID and ICUSTAY_ID are not empty in `stays.csv` files.\n",
    "* `stays.csv` and `events.csv` files are always present.\n",
    "* There is no case, where after initial filtering we cannot recover empty ICUSTAY_IDs.\n",
    "  \n",
    "Problems which are fixed by filtering up the events:\n",
    "* Remove all events for which HADM_ID is missing.\n",
    "* Remove all events for which HADM_ID is not present in `stays.csv`.\n",
    "* If ICUSTAY_ID is missing in an event and HADM_ID is not missing, then we look at `stays.csv` and try to recover ICUSTAY_ID.\n",
    "* Remove all events for which we cannot recover ICUSTAY_ID.\n",
    "* Remove all events for which ICUSTAY_ID is not present in `stays.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1 / 33798           \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreass2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2802: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 3001 / 33798           \n",
      "processed 6001 / 33798           \n",
      "processed 9001 / 33798           \n",
      "processed 12001 / 33798           \n",
      "processed 15001 / 33798           \n",
      "processed 18001 / 33798           \n",
      "processed 21001 / 33798           \n",
      "processed 24001 / 33798           \n",
      "processed 27001 / 33798           \n",
      "processed 30001 / 33798           \n",
      "processed 33001 / 33798           \n",
      "n_events: 253116833\n",
      "empty_hadm: 5162703\n",
      "no_hadm_in_stay: 32266173\n",
      "no_icustay: 15735688\n",
      "recovered: 15735688\n",
      "could_not_recover: 0\n",
      "icustay_missing_in_stays: 7115720\n"
     ]
    }
   ],
   "source": [
    "filter_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
