{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai.imports'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/DAT259/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_learner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastai.imports'"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ConvLearner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-692f14c9d66b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run '__init__.py'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mConvLearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ConvLearner' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_patients_data(path):\n",
    "    patients = pd.read_csv(os.path.join(path, 'PATIENTS.csv'))\n",
    "    patients = patients[['SUBJECT_ID', 'GENDER', 'DOB', 'DOD']]\n",
    "    patients.DOB = pd.to_datetime(patients.DOB)\n",
    "    patients.DOD = pd.to_datetime(patients.DOD)\n",
    "    return patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_admission_data(path):\n",
    "    admissions = pd.read_csv(os.path.join(path, 'ADMISSIONS.csv'))\n",
    "    admissions = admissions[['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'DEATHTIME', 'ETHNICITY', 'DIAGNOSIS']]\n",
    "    admissions.ADMITTIME = pd.to_datetime(admissions.ADMITTIME)\n",
    "    admissions.DISCHTIME = pd.to_datetime(admissions.DISCHTIME)\n",
    "    admissions.DEATHTIME = pd.to_datetime(admissions.DEATHTIME)\n",
    "    return admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_icd_diagnoses_data(path):\n",
    "    codes = pd.read_csv(os.path.join(path, 'D_ICD_DIAGNOSES.csv'))\n",
    "    codes = codes[['ICD9_CODE','SHORT_TITLE','LONG_TITLE']]\n",
    "    diagnoses = pd.read_csv(os.path.join(path, 'DIAGNOSES_ICD.csv'))\n",
    "    diagnoses = diagnoses.merge(codes, how='inner', left_on='ICD9_CODE', right_on='ICD9_CODE')\n",
    "    diagnoses[['SUBJECT_ID','HADM_ID','SEQ_NUM']] = diagnoses[['SUBJECT_ID','HADM_ID','SEQ_NUM']].astype(int)\n",
    "    return diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_inhospital_mortality_to_icustays(stays):\n",
    "    mortality = stays.DOD.notnull() & ((stays.ADMITTIME <= stays.DOD) & (stays.DISCHTIME >= stays.DOD))\n",
    "    mortality = mortality | (stays.DEATHTIME.notnull() & ((stays.ADMITTIME <= stays.DEATHTIME) & (stays.DISCHTIME >= stays.DEATHTIME)))\n",
    "    stays['MORTALITY'] = mortality.astype(int)\n",
    "    stays['MORTALITY_INHOSPITAL'] = stays['MORTALITY']\n",
    "    return stays\n",
    "\n",
    "def add_inunit_mortality_to_icustays(stays):\n",
    "    mortality = stays.DOD.notnull() & ((stays.INTIME <= stays.DOD) & (stays.OUTTIME >= stays.DOD))\n",
    "    mortality = mortality | (stays.DEATHTIME.notnull() & ((stays.INTIME <= stays.DEATHTIME) & (stays.OUTTIME >= stays.DEATHTIME)))\n",
    "    stays['MORTALITY_INUNIT'] = mortality.astype(int)\n",
    "    return stays\n",
    "\n",
    "def add_age_to_icustays(stays):\n",
    "    stays['AGE'] = (stays.INTIME - stays.DOB).apply(lambda s: s / np.timedelta64(1, 's')) / 60./60/24/365\n",
    "    stays.loc[stays.AGE<0,'AGE'] = 90\n",
    "    return stays\n",
    "\n",
    "def remove_icustays_with_transfers(stays):\n",
    "    stays = stays.loc[(stays.FIRST_WARDID == stays.LAST_WARDID) & (stays.FIRST_CAREUNIT == stays.LAST_CAREUNIT)]\n",
    "    return stays[['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'LAST_CAREUNIT', 'DBSOURCE', 'INTIME', 'OUTTIME', 'LOS']]\n",
    "\n",
    "def read_icustays_data(path):\n",
    "    stays = pd.read_csv(os.path.join(path, 'ICUSTAYS.csv'))\n",
    "    stays.INTIME = pd.to_datetime(stays.INTIME)\n",
    "    stays.OUTTIME = pd.to_datetime(stays.OUTTIME)\n",
    "    return stays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_on_subject(table1, table2):\n",
    "    return table1.merge(table2, how='inner', left_on=['SUBJECT_ID'], right_on=['SUBJECT_ID'])\n",
    "\n",
    "def merge_on_subject_admission(table1, table2):\n",
    "    return table1.merge(table2, how='inner', left_on=['SUBJECT_ID', 'HADM_ID'], right_on=['SUBJECT_ID', 'HADM_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_diagnoses_on_stays(diagnoses, stays):\n",
    "    return diagnoses.merge(stays[['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID']].drop_duplicates(), how='inner',\n",
    "                           left_on=['SUBJECT_ID', 'HADM_ID'], right_on=['SUBJECT_ID', 'HADM_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_icd_codes(diagnoses, output_path=None):\n",
    "    codes = diagnoses[['ICD9_CODE','SHORT_TITLE','LONG_TITLE']].drop_duplicates().set_index('ICD9_CODE')\n",
    "    codes['COUNT'] = diagnoses.groupby('ICD9_CODE')['ICUSTAY_ID'].count()\n",
    "    codes.COUNT = codes.COUNT.fillna(0).astype(int)\n",
    "    codes = codes.loc[codes.COUNT>0]\n",
    "    if output_path:\n",
    "        codes.to_csv(output_path, index_label='ICD9_CODE')\n",
    "    return codes.sort_values('COUNT', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def break_up_stays_by_subject(stays, output_path, subjects=None, verbose=1):\n",
    "    subjects = stays.SUBJECT_ID.unique() if subjects is None else subjects\n",
    "    nb_subjects = subjects.shape[0]\n",
    "    for i, subject_id in enumerate(subjects):\n",
    "        if verbose:\n",
    "            sys.stdout.write('\\rSUBJECT {0} of {1}...'.format(i+1, nb_subjects))\n",
    "        dn = os.path.join(output_path, str(subject_id))\n",
    "        try:\n",
    "            os.makedirs(dn)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        stays.loc[stays.SUBJECT_ID == subject_id].sort_values(by='INTIME').to_csv(os.path.join(dn, 'stays.csv'), index=False)\n",
    "    if verbose:\n",
    "        sys.stdout.write('DONE!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def break_up_diagnoses_by_subject(diagnoses, output_path, subjects=None, verbose=1):\n",
    "    subjects = diagnoses.SUBJECT_ID.unique() if subjects is None else subjects\n",
    "    nb_subjects = subjects.shape[0]\n",
    "    for i, subject_id in enumerate(subjects):\n",
    "        if verbose:\n",
    "            sys.stdout.write('\\rSUBJECT {0} of {1}...'.format(i+1, nb_subjects))\n",
    "        dn = os.path.join(output_path, str(subject_id))\n",
    "        try:\n",
    "            os.makedirs(dn)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        diagnoses.loc[diagnoses.SUBJECT_ID == subject_id].sort_values(by=['ICUSTAY_ID','SEQ_NUM']).to_csv(os.path.join(dn, 'diagnoses.csv'), index=False)\n",
    "    if verbose:\n",
    "        sys.stdout.write('DONE!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_events_table_by_row(path, table):\n",
    "    nb_rows = { 'chartevents': 330712484, 'labevents': 27854056, 'outputevents': 4349219 }\n",
    "    reader = csv.DictReader(open(os.path.join(path, table.upper() + '.csv'), 'r'))\n",
    "    for i,row in enumerate(reader):\n",
    "        if 'ICUSTAY_ID' not in row:\n",
    "            row['ICUSTAY_ID'] = ''\n",
    "        yield row, i, nb_rows[table.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_events_table_and_break_up_by_subject(path, table, output_path, items_to_keep=None, subjects_to_keep=None, verbose=1):\n",
    "    obs_header = [ 'SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'CHARTTIME', 'ITEMID', 'VALUE', 'VALUEUOM' ]\n",
    "    if items_to_keep is not None:\n",
    "        items_to_keep = set([ str(s) for s in items_to_keep ])\n",
    "    if subjects_to_keep is not None:\n",
    "        subjects_to_keep = set([ str(s) for s in subjects_to_keep ])\n",
    "\n",
    "    class DataStats(object):\n",
    "        def __init__(self):\n",
    "            self.curr_subject_id = ''\n",
    "            self.last_write_no = 0\n",
    "            self.last_write_nb_rows = 0\n",
    "            self.last_write_subject_id = ''\n",
    "            self.curr_obs = []\n",
    "\n",
    "    data_stats = DataStats()\n",
    "\n",
    "    def write_current_observations():\n",
    "        data_stats.last_write_no += 1\n",
    "        data_stats.last_write_nb_rows = len(data_stats.curr_obs)\n",
    "        data_stats.last_write_subject_id = data_stats.curr_subject_id\n",
    "        dn = os.path.join(output_path, str(data_stats.curr_subject_id))\n",
    "        try:\n",
    "            os.makedirs(dn)\n",
    "        except:\n",
    "            pass\n",
    "        fn = os.path.join(dn, 'events.csv')\n",
    "        if not os.path.exists(fn) or not os.path.isfile(fn):\n",
    "            f = open(fn, 'w')\n",
    "            f.write(','.join(obs_header) + '\\n')\n",
    "            f.close()\n",
    "        w = csv.DictWriter(open(fn, 'a'), fieldnames=obs_header, quoting=csv.QUOTE_MINIMAL)\n",
    "        w.writerows(data_stats.curr_obs)\n",
    "        data_stats.curr_obs = []\n",
    "    \n",
    "    for row, row_no, nb_rows in read_events_table_by_row(path, table):\n",
    "        if verbose and (row_no % 100000 == 0):\n",
    "            if data_stats.last_write_no != '':\n",
    "                sys.stdout.write('\\rprocessing {0}: ROW {1} of {2}...last write '\n",
    "                                 '({3}) {4} rows for subject {5}'.format(table, row_no, nb_rows,\n",
    "                                                                         data_stats.last_write_no,\n",
    "                                                                         data_stats.last_write_nb_rows,\n",
    "                                                                         data_stats.last_write_subject_id))\n",
    "            else:\n",
    "                sys.stdout.write('\\rprocessing {0}: ROW {1} of {2}...'.format(table, row_no, nb_rows))\n",
    "        \n",
    "        if (subjects_to_keep is not None and row['SUBJECT_ID'] not in subjects_to_keep):\n",
    "            continue\n",
    "        if (items_to_keep is not None and row['ITEMID'] not in items_to_keep):\n",
    "            continue\n",
    "        \n",
    "        row_out = { 'SUBJECT_ID': row['SUBJECT_ID'],\n",
    "                    'HADM_ID': row['HADM_ID'],\n",
    "                    'ICUSTAY_ID': '' if 'ICUSTAY_ID' not in row else row['ICUSTAY_ID'],\n",
    "                    'CHARTTIME': row['CHARTTIME'],\n",
    "                    'ITEMID': row['ITEMID'],\n",
    "                    'VALUE': row['VALUE'],\n",
    "                    'VALUEUOM': row['VALUEUOM'] }\n",
    "        if data_stats.curr_subject_id != '' and data_stats.curr_subject_id != row['SUBJECT_ID']:\n",
    "            write_current_observations()\n",
    "        data_stats.curr_obs.append(row_out)\n",
    "        data_stats.curr_subject_id = row['SUBJECT_ID']\n",
    "        \n",
    "    if data_stats.curr_subject_id != '':\n",
    "        write_current_observations()\n",
    "\n",
    "    if verbose:\n",
    "        sys.stdout.write('\\rfinished processing {0}: ROW {1} of {2}...last write '\n",
    "                         '({3}) {4} rows for subject {5}...DONE!\\n'.format(table, row_no, nb_rows,\n",
    "                                                                 data_stats.last_write_no,\n",
    "                                                                 data_stats.last_write_nb_rows,\n",
    "                                                                 data_stats.last_write_subject_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_admissions_on_nb_icustays(stays, min_nb_stays=1, max_nb_stays=1):\n",
    "    to_keep = stays.groupby('HADM_ID').count()[['ICUSTAY_ID']].reset_index()\n",
    "    to_keep = to_keep.loc[(to_keep.ICUSTAY_ID>=min_nb_stays)&(to_keep.ICUSTAY_ID<=max_nb_stays)][['HADM_ID']]\n",
    "    stays = stays.merge(to_keep, how='inner', left_on='HADM_ID', right_on='HADM_ID')\n",
    "    return stays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
